{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "> Started with initial copy-paste of [torchgde][torchgde]\n",
    "\n",
    "[torchgde]: https://github.com/Zymrael/gde/blob/master/torchgde/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils from `torchgde` \n",
    "**NOTE:** These are not used but are kept around as legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn, torch.nn.functional as F\n",
    "\n",
    "class PerformanceContainer(object):\n",
    "    \"\"\" Simple data class for metrics logging.\"\"\"\n",
    "    def __init__(self, data:dict):\n",
    "        self.data = data\n",
    "        \n",
    "    @staticmethod\n",
    "    def deep_update(x, y):\n",
    "        for key in y.keys():\n",
    "            x.update({key: list(x[key] + y[key])})\n",
    "        return x\n",
    "    \n",
    "def accuracy(y_hat:torch.Tensor, y:torch.Tensor):\n",
    "    \"\"\" Standard percentage accuracy computation \"\"\"\n",
    "    preds = torch.max(y_hat, 1)[1]\n",
    "    return torch.mean((y == preds).float())\n",
    "\n",
    "\n",
    "class MAPELoss(nn.Module):\n",
    "    \n",
    "    def forward(self, estimation:torch.Tensor, target:torch.Tensor):\n",
    "        AER = torch.abs((target - estimation) / (target + 1e-10))  # Absolute error ratio\n",
    "        MAPE = AER.mean() * 100\n",
    "        return MAPE\n",
    "\n",
    "class MAELoss(nn.Module):\n",
    "    \n",
    "    def forward(self, estimation:torch.Tensor, target:torch.Tensor):\n",
    "        AE = torch.abs(target - estimation)\n",
    "        MAE = AE.mean()\n",
    "        return MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def set_timestamps(timestamps):\n",
    "    return [timestamps[i].unique() for i in range(len(timestamps))]\n",
    "\n",
    "\n",
    "def get_indices(timestamps, set_ts, bs):\n",
    "    all_idx = []\n",
    "    for i in range(len(set_ts)):\n",
    "        idx = []\n",
    "        for j in range(bs):\n",
    "            idx.append((set_ts[i] == timestamps[i][j]).nonzero().item())\n",
    "        all_idx.append(idx)\n",
    "    return all_idx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| export\n",
    "import itertools, math, numpy as np, pandas as pd\n",
    "import dgl, dgl.function as fn\n",
    "\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "import torchdiffeq\n",
    "\n",
    "from typing import Callable, Union, Literal\n",
    "\n",
    "def get_device() -> Literal['cuda', 'cpu']:\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def is_list_like(obj) -> bool:\n",
    "    '''\n",
    "    Tests if obj is like a list\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    obj\n",
    "        A python object.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    result\n",
    "        Whether or not `obj` is a list, numpy array, pandas series or pytorch tensor.\n",
    "    '''\n",
    "    list_like = (\n",
    "        np.ndarray, pd.Series, torch.Tensor,\n",
    "    )\n",
    "    list_types = tuple(map(str, map(type, list_like)))\n",
    "    if isinstance(obj, list_like) or isinstance(obj, list):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def torch_t(\n",
    "    t:Union[int, float, list, torch.Tensor], \n",
    "    device:Union[str, torch.device]=None, \n",
    "    append_zero:bool=False\n",
    ") -> torch.Tensor:\n",
    "    '''\n",
    "    Creates the time tensor used with Neural ODEs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t\n",
    "        The time (index or list) to convert.\n",
    "    \n",
    "    device\n",
    "        Device on which to put the tensor.\n",
    "\n",
    "    append_zero\n",
    "        Whether or not a 0 should come before `t` e.g. `tensor([0, 1])` if `t=1`.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    time_tensor\n",
    "        Given `t` as a tensor.\n",
    "    '''\n",
    "    # Make sure t is a torch Tensor\n",
    "    if not is_list_like(t):\n",
    "        # Just a single value, integrate [0, t]\n",
    "        if append_zero:\n",
    "            t = torch.tensor([0, t]).float()\n",
    "        # Just a single value, integrate [t]\n",
    "        else:\n",
    "            t = torch.tensor(t)\n",
    "\n",
    "    elif torch.is_tensor(t):\n",
    "        pass\n",
    "    # is a list, but not already a torch tensor\n",
    "    else:\n",
    "        if append_zero:\n",
    "            t = torch.tensor([0, *t]).float()\n",
    "        else:\n",
    "            t = torch.tensor(t)\n",
    "\n",
    "    # Put t on correct device    \n",
    "    if device is not None:\n",
    "        t = t.to(device)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_torchdiffeq_solver(adjoint:bool)->Callable:\n",
    "    '''\n",
    "    Gets corresponding ode integration function depending on boolean flag\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    adjoint\n",
    "        Whether to use adjoint or not.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    solver\n",
    "        Either torchdiffeq.odeint_adjoint or torchdiffeq.odeint\n",
    "    '''\n",
    "    func_str = 'odeint_adjoint' if adjoint else 'odeint'\n",
    "    return getattr(torchdiffeq, func_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def to_np(tensor):\n",
    "    return tensor.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def make_imap(dictionary:dict) -> dict:\n",
    "    return {v:k for k, v in dictionary.items()}\n",
    "\n",
    "def dict_diff(dict_a:dict, dict_b:dict) -> dict:\n",
    "    return {\n",
    "        ka: va for i, (ka, va) in enumerate(dict_a.items())\n",
    "        if ka not in dict_b\n",
    "    }\n",
    "\n",
    "def dict_if_in(dict_a:dict, dict_b:dict) -> dict:\n",
    "    return {\n",
    "        ka: va for i, (ka, va) in enumerate(dict_a.items())\n",
    "        if ka in dict_b\n",
    "    }\n",
    "\n",
    "def dict_imap_if_in(dict_a:dict, dict_b:dict) -> dict:\n",
    "    '''\n",
    "    NOTE: equivalent to make_imap(dict_if_in(a, b))\n",
    "    '''\n",
    "    return {\n",
    "        va: ka for ia, (ka, va) in enumerate(dict_a.items())\n",
    "        if ka in dict_b\n",
    "    }\n",
    "\n",
    "\n",
    "def reverse_lookup(dictionary, value):\n",
    "    imap = make_imap(dictionary)\n",
    "    if value in imap:\n",
    "        return imap[value]\n",
    "    return None\n",
    "\n",
    "def can_imap(imap, key, omap):\n",
    "    return imap[key] in omap\n",
    "\n",
    "def invert_imap_lookup(imap, key, omap):\n",
    "    if can_imap(imap, key, omap):\n",
    "        return omap[imap[key]]\n",
    "    return None\n",
    "\n",
    "def all_imappable(arr, imap, omap):\n",
    "    return all([can_imap(imap, e, omap) for e in arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def generate_steps(groups):\n",
    "    return list(zip(groups[:-1], groups[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def make_time_lambdas(time_bins):\n",
    "    lambdas = np.array([\n",
    "        (i + 1) / len(time_bins)\n",
    "        for i in time_bins\n",
    "    ])\n",
    "    lambdas /= lambdas.sum()\n",
    "    return lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def aggregate_loss_over_time(\n",
    "    data_ti, \n",
    "    data_tp, \n",
    "    criterion:Callable,\n",
    "    aggregation:Literal['mean', 'sum']='mean',\n",
    "    lambdas:Union[np.ndarray, list]=None\n",
    "):\n",
    "    n_timepoints = data_tp.size(0)\n",
    "    if lambdas is None:\n",
    "        lambdas = np.ones_like(np.arange(n_timepoints))\n",
    "    \n",
    "    losses = sum([\n",
    "        lambdas[i] * criterion(data_tp[i], data_ti[i]) \n",
    "        for i in range(1, n_timepoints)\n",
    "    ])\n",
    "\n",
    "    if aggregation == 'mean':\n",
    "        losses /= n_timepoints\n",
    "        \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def dearray(arr):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr\n",
    "        the array like object (tensor, numpy array, list of elements) to cast itself \n",
    "            and all of its list-like elements back to a python list\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    arr\n",
    "        the array as a python list with all of its list-like elements also as python lists    \n",
    "    '''\n",
    "    if is_list_like(arr):\n",
    "        if torch.is_tensor(arr):\n",
    "            arr = to_np(arr)#.detach().cpu().numpy()\n",
    "\n",
    "        if isinstance(arr, np.ndarray):\n",
    "            arr = arr.tolist()\n",
    "        \n",
    "        arr = [dearray(el) for el in arr]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
