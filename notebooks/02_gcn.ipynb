{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN\n",
    "\n",
    "> Started with initial copy-paste of [torchgde][torchgde]\n",
    "\n",
    "[torchgde]: https://github.com/Zymrael/gde/blob/master/torchgde/models/gcn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp gcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import math, numpy as np\n",
    "import dgl, dgl.function as fn\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "from gode.graph import dgl_norm\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self, g:dgl.DGLGraph, \n",
    "        in_feats:int, out_feats:int, \n",
    "        activation:Callable[[torch.Tensor], torch.Tensor],\n",
    "        dropout:int, bias:bool=True, msg_fn:Callable=fn.sum\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.g = g\n",
    "        self.msg_fn = msg_fn\n",
    "        self.weight = nn.Parameter(torch.Tensor(in_feats, out_feats))\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_feats))\n",
    "        else:\n",
    "            self.bias = None\n",
    "        \n",
    "        self.activation = activation\n",
    "        if dropout:\n",
    "            self.dropout = nn.Dropout(p=dropout)\n",
    "        else:\n",
    "            self.dropout = 0.\n",
    "\n",
    "        if 'norm' not in g.ndata:            \n",
    "            self.g = dgl_norm(g)\n",
    "            \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, h):\n",
    "        if self.dropout:\n",
    "            h = self.dropout(h)\n",
    "        h = torch.mm(h, self.weight)\n",
    "\n",
    "        # normalization by square root of src degree\n",
    "        h = h * self.g.ndata['norm']\n",
    "        self.g.ndata['h'] = h\n",
    "        self.g.update_all(\n",
    "            fn.copy_src(src='h', out='m'), \n",
    "            self.msg_fn(msg='m', out='h')\n",
    "        )\n",
    "        \n",
    "        h = self.g.ndata.pop('h')\n",
    "        \n",
    "        # normalization by square root of dst degree\n",
    "        h = h * self.g.ndata['norm']\n",
    "        \n",
    "        # bias\n",
    "        if self.bias is not None:\n",
    "            h = h + self.bias\n",
    "        \n",
    "        if self.activation:\n",
    "            h = self.activation(h)\n",
    "        \n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_layers:int, \n",
    "        g:dgl.DGLGraph, \n",
    "        in_feats:int, hidden_feats:int, out_feats:int, \n",
    "        activation:Callable, dropout:int, bias=True\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        self.layers.append(GCNLayer(g, in_feats, hidden_feats, activation, dropout))\n",
    "\n",
    "        for i in range(num_layers - 2):\n",
    "            self.layers.append(GCNLayer(g, hidden_feats, hidden_feats, activation, dropout))\n",
    "\n",
    "        self.layers.append(GCNLayer(g, hidden_feats, out_feats, None, 0.))\n",
    "\n",
    "    def set_graph(self, g):\n",
    "        for l in self.layers:\n",
    "            l.g = g\n",
    "\n",
    "    def forward(self, features):\n",
    "        h = features\n",
    "        for layer in self.layers:\n",
    "            h = layer(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
