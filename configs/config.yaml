# RiTINI Model Configuration
# ===========================

# Device configuration
device: auto  # 'auto', 'cuda', or 'cpu'

# Data paths
data:
  raw:
    trajectory_file: data/raw/traj_data.npy
    gene_names_file: data/raw/gene_names.txt
    interest_genes_file: data/raw/interest_genes.txt

  prior_graph_mode: fully_connected  # Options: granger_causality, fully_connected, identity, zeros
  n_highly_variable_genes: 100  # Number of highly variable genes to select
  
  processed:
    trajectory_file: data/processed/trajectory.npy
    gene_names_file: data/processed/gene_names.txt
    prior_graph_adjacency_file: data/processed/prior_adjacency.npy


# Data batching
batching:
  batch_size: 4
  time_window: 5  # Length of time_window, set to null to use all timepoints

# Model architecture
model:
  in_features: 1      # Each node has 1 feature (gene expression)
  out_features: 1     # Predict 1 feature per node
  n_heads: 1
  feat_dropout: 0.1
  attn_dropout: 0.1
  negative_slope: 0.2
  input_latent_dim: 16  # Dimension of latent space for input features
  history_length: 5  # Number of past timepoints to use for each prediction
  residual: false
  activation: tanh    # Options: tanh, relu, leaky_relu, elu, gelu
  bias: true
  ode_method: rk4  # Options: euler, rk4

# Training parameters
training:
  n_epochs: 200
  learning_rate: 0.001

# Loss configuration
loss:
  graph_reg_weight: 0.00  # Weight for graph regularization loss

# Learning rate scheduler
scheduler:
  type: reduce_on_plateau
  factor: 0.5
  patience: 10
  mode: min

# Output configuration
output:
  dir: output
  save_best_model: true
  save_history: true
  print_every: 10  # Print progress every N epochs