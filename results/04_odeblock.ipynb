{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ODEBlock\n",
    "\n",
    "> Started with initial copy-paste of [torchgde][torchgde]\n",
    "\n",
    "[torchgde]: https://github.com/Zymrael/gde/blob/master/torchgde/models/odeblock.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp odeblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn, torchdiffeq\n",
    "\n",
    "from gode.utils import get_torchdiffeq_solver, torch_t\n",
    "\n",
    "class ODEBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        func:nn.Module, \n",
    "        method:str='dopri5', \n",
    "        rtol:float=1e-3, \n",
    "        atol:float=1e-4, \n",
    "        adjoint:bool=True\n",
    "    ):\n",
    "        \"\"\" Standard ODEBlock class. Can handle all types of ODE functions\n",
    "            :method:str = {'euler', 'rk4', 'dopri5', 'adams'}\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.method = method\n",
    "        self.adjoint = adjoint\n",
    "        self.atol = atol\n",
    "        self.rtol = rtol\n",
    "\n",
    "    def forward(\n",
    "        self, x:torch.Tensor, t:torch.Tensor, \n",
    "        return_whole_sequence:bool=False,\n",
    "        adjoint:bool=None\n",
    "    ):\n",
    "        t = torch_t(t)\n",
    "        t = t.to(x.device).type_as(x)\n",
    "        \n",
    "        solver = get_torchdiffeq_solver(self.adjoint if adjoint is None else adjoint)     \n",
    "        out = solver(\n",
    "            self.func, x, t,\n",
    "            rtol=self.rtol, atol=self.atol, method=self.method\n",
    "        ) \n",
    "        \n",
    "        if not return_whole_sequence:\n",
    "            out = out[-1]\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def forward_batched(self, x:torch.Tensor, nn:int, indices:list, timestamps:set):\n",
    "        \"\"\" Modified forward for ODE batches with different integration times \"\"\"\n",
    "        t = torch.Tensor(list(timestamps))\n",
    "        out = self.forward(x, t, return_whole_sequence=True)        \n",
    "        out = self._build_batch(out, nn, indices).reshape(x.shape)\n",
    "        return out\n",
    "    \n",
    "    def _build_batch(self, odeout, nn, indices):\n",
    "        b_out = []\n",
    "        for i in range(len(indices)):\n",
    "            b_out.append(odeout[indices[i], i*nn:(i+1)*nn])\n",
    "        return torch.cat(b_out).to(odeout.device)              \n",
    "        \n",
    "    def trajectory(self, x:torch.Tensor, t_end:int, num_points:int):\n",
    "        t = torch.linspace(0, t_end, num_points).type_as(x).to(x.device)\n",
    "        out = self.forward(x, t, return_whole_sequence=True, adjoint=False)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
